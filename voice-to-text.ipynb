{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def list_audio_devices():\n",
    "    p = pyaudio.PyAudio()\n",
    "    info = p.get_host_api_info_by_index(0)\n",
    "    num_devices = info.get('deviceCount')\n",
    "    \n",
    "    print(\"Dispositivos de entrada de audio disponibles:\")\n",
    "    \n",
    "    for i in range(num_devices):\n",
    "        device_info = p.get_device_info_by_host_api_device_index(0, i)\n",
    "        device_name = device_info['name']\n",
    "        print(f\"Índice {i}: {device_name}\")\n",
    "\n",
    "def record_audio_with_device(filename, seconds, device_index):\n",
    "    # Configuración de la grabación\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    \n",
    "    # Inicializar el objeto PyAudio\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Abrir el flujo de entrada de audio con el dispositivo seleccionado\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK,\n",
    "                        input_device_index=device_index)\n",
    "\n",
    "    print(f\"Grabando durante {seconds} segundos con el dispositivo {device_index}...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    # Grabar audio en trozos y guardar los fragmentos en la lista de frames\n",
    "    for _ in range(0, int(RATE / CHUNK * seconds)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"¡Grabación completa!\")\n",
    "\n",
    "    # Detener y cerrar el flujo de audio\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    # Terminar PyAudio\n",
    "    audio.terminate()\n",
    "\n",
    "    # Guardar la grabación en un archivo WAV\n",
    "    with wave.open(filename, 'wb') as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "def extraer_key_de_json(nombre_archivo):\n",
    "    try:\n",
    "        with open(nombre_archivo, \"r\") as archivo:\n",
    "            data = json.load(archivo)\n",
    "            clave_key = data.get(\"key\")\n",
    "            if clave_key is not None:\n",
    "                return str(clave_key)\n",
    "            else:\n",
    "                return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"El archivo {nombre_archivo} no se encuentra.\")\n",
    "        return None\n",
    "    except KeyError:\n",
    "        print(f\"La clave 'key' no está presente en el archivo JSON.\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"El archivo {nombre_archivo} no es un JSON válido.\")\n",
    "        return None\n",
    "\n",
    "archivo_json = \"./credentials/openai_key.json\"\n",
    "valor_key = extraer_key_de_json(archivo_json)\n",
    "openai.api_key = valor_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabando durante 5 segundos con el dispositivo 1...\n",
      "¡Grabación completa!\n",
      "Hello, hello.\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso:\n",
    "if __name__ == \"__main__\":\n",
    "    record_name = './data/output/record.wav'\n",
    "    selected_device_index = 1  # Reemplaza esto con el índice del dispositivo que desees utilizar\n",
    "    record_audio_with_device(record_name, 5, selected_device_index)\n",
    "    audio_file = open(record_name, 'rb')\n",
    "    transcript = openai.Audio.transcribe('whisper-1', audio_file)\n",
    "\n",
    "    print(transcript['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
